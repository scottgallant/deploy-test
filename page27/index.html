<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <title>paperplanes. mathias meyer.</title>
    <meta name="robots" content="index,follow"/>
    <meta name="mssmarttagspreventparsing" content="true"/>
    <link rel="shortcut icon" href="/images/favicon.gif" type="image/gif" />
    <link rel="icon" href="/images/favicon.gif" type="image/gif" />
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
  	<meta name="author" content="Mathias Meyer"/>
    <meta name="dc.title" content="paperplanes. mathias meyer."/>
  	<link rel="start" href="http://www.paperplanes.de" title="paperplanes"/>
    
    <link href="http://www.paperplanes.de/rss.xml" rel="alternate" title="Primary Feed" type="application/rss+xml" />
    <link href="/stylesheets/screen.css" media="screen" rel="Stylesheet" title="paperplanes" type="text/css" />
    <link rel="stylesheet" type="text/css" href="/stylesheets/mobile.css" media="handheld, only screen and (max-device-width: 960px)" />
  </head>
  
  <body id="www-paperplanes-de">
    <div id="head">
      <div id="header-content">
        <a href="/">
          <img src="/images/paperplane.png" id="paperplane">
        </a>
        <div id="about">
          <h1 class="default">Hi, I'm Mathias Meyer, nice to meet you!</h1>
          <h1 class="mobile">Hi, I'm <a href="https://twitter.com/roidrage">Mathias Meyer</a>, I'm the CEO at <a href="https://travis-ci.com">Travis CI</a></h1>
          <p style="color: white" class="about-sub-title default">
            I'm the CEO at <a href="http://travis-ci.com">Travis CI</a>. I like coffee, <a href="https://twitter.com/roidrage">Twitter</a> and <a href="mailto:meyer@paperplanes.de">email</a>.
          </p>
        </div>
      </div>
    </div>

    <div id="box">
      <div id="content">
        <div id="articles">

  <article>
    <div class="item">
      <div class="item_details">
        <h3><a href="/2011/12/9/the-magic-of-consistent-hashing.html">The Simple Magic of Consistent Hashing</a></h3>
        <h4><a href="/2011/12/9/the-magic-of-consistent-hashing.html" title="The Simple Magic of Consistent Hashing">09 December 2011</a> by <a href="http://twitter.com/roidrage">Mathias Meyer</a></h4>
      </div>
      <div class="item_content">
        <p>The simplicity of consistent hashing is pretty mind-blowing. Here you have a
number of nodes in a cluster of databases, or in a cluster of web caches. How do
you figure out where the data for a particular key goes in that cluster?</p>

<p>You apply a hash function to the key. That&#39;s it?  Yeah, that&#39;s the whole deal of
consistent hashing. It&#39;s in the name, isn&#39;t it?</p>

<p>The same key will always return the same hash code (hopefully), so once you&#39;ve
figured out how you spread out a range of keys across the nodes available, you
can always find the right node by looking at the hash code for a key.</p>

<p>It&#39;s pretty ingenious, if you ask me. It was cooked up in the lab chambers at
Akamai, back in the late nineties. You should go and <a href="http://www.akamai.com/dl/technical_publications/ConsistenHashingandRandomTreesDistributedCachingprotocolsforrelievingHotSpotsontheworldwideweb.pdf" title="Akamai - Consistent Hashing and Random Trees">read the original paper
right after we&#39;re done here</a>.</p>

<p>Consistent hashing solves the problem people desperately tried to apply sharding
to pretty nicely and elegantly. I&#39;m not going to bore you with the details on
how exactly consistent hashing works. <a href="http://www.mikeperham.com/2009/01/14/consistent-hashing-in-memcache-client/" title="Mike Perham - Consistent Hashing in memcache-client">Mike Perham</a> does a pretty good job at
that already, and there are <a href="http://www.tomkleinpeter.com/2008/03/17/programmers-toolbox-part-3-consistent-hashing/" title="Tom Peter - Programmerâ€™s Toolbox Part 3: Consistent Hashing">many more blog posts</a> explaining
<a href="http://www.lexemetech.com/2007/11/consistent-hashing.html" title="Tom White - Consistent Hashing">implementations</a> and <a href="http://michaelnielsen.org/blog/consistent-hashing/" title="Michael Nielsen - Consistent Hashing">theory behind it</a>. Also, that <a href="http://twitter.com/riakhandbook">little upcoming
book</a> of mine has a full-length explanation
too. Here&#39;s a graphic showing the basic idea of consistent hashing, courtesy of
Basho.</p>

<p><img src="http://paperplanes-assets.s3.amazonaws.com/consistent-hashing.png" alt="Consistent Hashing"></p>

<p>Instead I want to look at the practical implications of consistent hashing in
distributed databases and cache farms.</p>

<h3>Easier to Avoid Hotspots</h3>

<p>When you put data on nodes based on a random result, which is what the hash
function calculates, a value that&#39;s a lot more random than the key it&#39;s based
on, it&#39;s easier to avoid hotspots. Why?</p>

<p>Assume a key based on an increasing value, or a simple range of keys, based on
the hour of the day, like <code>2011-12-11-13</code>. You add new hours and therefore new
data as time passes, and keys are stored based on the range they fall in. For
example, the keys <code>2011-12-11-18</code> until <code>2011-12-11-23</code> are stored on the same
node, with the rest of the keys stored on other nodes, just because the ranges
or the partitioning scheme happen to be set up this way.</p>

<p>For a consumer-facing site, the evening hours are usually the busiest time of
the day. They create more data, more writes, and possibly more reads too. For
the hours between 18:00 and 23:00, all the load goes to the single node that
carries all the relevant data.</p>

<p>But when you determine the location in the cluster based solely on the hash of
the key, chances are much higher that two keys lexicographically close to each
other end up on different nodes. Thus, the load is shared more evenly. The
disadvantage is that you lose the order of keys.</p>

<p>There are partitioning schemes that can work around this, even with a
range-based key location. HBase (and Google&#39;s BigTable, for that matter) stores
ranges of data in separate tablets. As tablets grow beyond their maximum size,
they&#39;re split up and the remaining parts re-distributed. The advantage of this
is that the original range is kept, even as you scale up.</p>

<h3>Consistent Hashing Enables Partitioning</h3>

<p>When you have a consistent hash, everything looks like a partition. The idea is
simple. Consistent hashing forms a keyspace, which is also called continuum, as
presented in the illustration. As a node joins the cluster, it picks a random
number, and that number determines the data it&#39;s going to be responsible for.
Everything between this number and one that&#39;s next in the ring and that has
been picked by a different node previously, is now belong to this node. The
resulting partition could be of any size theoretically. It could be a tiny
slice, or a large one.</p>

<p>First implementations of consistent hashing still had the problem that a node
picking a random range of keys resulted in one node potentially carrying a
larger keyspace than others, therefore still creating hotspots.</p>

<p>But the improvement was as simple as it was ingenious. A hash function has a
maximum result set, a SHA-1 function has a bit space of 2^160. You do the
math. Instead of picking a random key, a node could choose from a fixed set of
partitions, like equally size pizza slices. But instead of picking the one with
the most cheese on, everyone gets an equally large slice. The number of
partitions is picked up front, and practically never changes over the lifetime
of the cluster.</p>

<p>For good measure, here&#39;s a picture of a sliced pizza.</p>

<p><img src="http://paperplanes-assets.s3.amazonaws.com/consistent-pizza.jpg" alt="Consistent Pizza"></p>

<h3>Partitioning Makes Scaling Up and Down More Predictable</h3>

<p>With a fixed number of partitions of the same size, adding new nodes becomes
even less of a burden than with just consistent hashing. With the former, it was
still unpredictable how much data had to be moved around to transfer ownership
of all the data in the range of the new node. One thing&#39;s for sure, it already
involved a lot less work than previous methods of sharding data.</p>

<p>With partitioning, a node simply claims partitions, and either explicitly or
implicitly asks the current owners to hand off the data to them. As a partition
can only contain so many keys, and randomness ensures a somewhat even spread of
data, there&#39;s a lot less unpredictability about the data that needs to be
transferred.</p>

<p>If that partitions just so happens to carry the largest object by far in you
whole cluster, that&#39;s something even consistent hashing can&#39;t solve. It only
cares for keys.</p>

<p>Going back to HBase, it cares for keys and the size of the tablet the data is
stored in, as it breaks up tablets once they reach a threshold.  Breaking up and
reassigning a tablet requires coordination, which is not an easy thing to do in
a distributed system.</p>

<h3>Consistent Hashing and Partitioning Enable Replication</h3>

<p>Consistent hashing made one thing a lot easier: replicating data across several
nodes. The primary means for replication is to ensure data survives single or
multiple machine failures. The more replicas you have, the more likely is your
data to survive one or more hardware crashes. With three replicas, you can
afford to lose two nodes and still serve the data.</p>

<p>With a fixed set of partitions, a new node can just pick the ones it&#39;s
responsible for, and another stack of partitions it&#39;s going to be a replica for.
When you really think about it, both processes are actually the same. The beauty
of consistent hashing is that there doesn&#39;t need to be master for any piece of
data. Every node is simply a replica of a number of partitions.</p>

<p>But replication has another purpose besides ensuring data availability.</p>

<h3>Replication Reduces Hotspots (Even More!!!)</h3>

<p>Having more than one replica of a single piece of data means you can spread out
the request load even more. With three replicas of that data, residing on three
different nodes, you can now load-balance between them. Neat!</p>

<p>With that, consistent hashing enables a pretty linear increase in capacity as you
add more nodes to a cluster.</p>

<h3>Consistent Hashing Enables Scalability and Availability</h3>

<p>Consistent hashing allows you to scale up and down easier, and makes ensuring
availability easier. Easier ways to replicate data allows for better
availability and fault-tolerance. Easier ways to reshuffle data when nodes come
and go means simpler ways to scale up and down.</p>

<p>It&#39;s an ingenious invention, one that has had a great impact. Look at the likes
of <a href="http://memcached.org/" title="Memcached">Memcached</a>, <a href="http://www.allthingsdistributed.com/2007/10/amazons_dynamo.html" title="Amazon Dynamo">Amazon&#39;s Dynamo</a>, <a href="http://cassandra.apache.org/" title="Cassandra">Cassandra</a>, or <a href="http://basho.com/products/riak-overview/" title="Riak">Riak</a>. They all
adopted consistent hashing in one way or the other to ensure scalability and
availability.</p>

<p>Want to know more about distributed databases in general and Riak in particular?
You&#39;ll like the <a href="http://riakhandbook.com/">Riak Handbook</a>, a hands-on
guide full of practical examples and advice on how to use Riak to ensure
scalability and availability for your data.</p>

<p>In the next installment we&#39;re looking at the consequences and implications of
losing key ordering in a Riak cluster.</p>

      </div>
      <div class="item_meta">
        <span class="item_tags">
          Tags: 
          
        </span>
      </div>
    </div>
  </article>

  <article>
    <div class="item">
      <div class="item_details">
        <h3><a href="/2011/9/7/an-update-on-the-nosql-handbook.html">An Update On The NoSQL Handbook</a></h3>
        <h4><a href="/2011/9/7/an-update-on-the-nosql-handbook.html" title="An Update On The NoSQL Handbook">07 September 2011</a> by <a href="http://twitter.com/roidrage">Mathias Meyer</a></h4>
      </div>
      <div class="item_content">
        <p>A couple of months ago I set out to write a <a href="http://nosqlhandbook.com">book on
NoSQL</a>. It&#39;s about time I give an update on how it&#39;s
been going, and when you can expect a book in your hands, or rather, on your
screen.</p>

<p>After an initial burst of writing, I took somewhat of a break, so please excuse
the delay in general. I spent the last weeks writing (a lot), and I&#39;m currently
trying to polish and finish up the existing content so that I can throw
something out there for the world to peek at. Currently, the book covers
MongoDB, Riak and Redis in varying detail, and I&#39;m working to finish up loose
ends to get into a good shape, before I&#39;m starting work on more chapters.</p>

<p>A lot of people have asked me about pricing, distribution model, updates, and so
on, so I&#39;m following up with an FAQ section. In general, I&#39;m as keen to get
something out there as people have expressed their interest in reading it,
believe me.</p>

<p>Turns out though: writing a book is hard. It takes a lot of work, a lot of
discipline and creativity to come up with the right words and code examples. I&#39;m
not complaining, it&#39;s just something you don&#39;t realize from writing even
slightly longer blog posts. It&#39;s still an incredible learning experience too,
because I (and you) get to play with pretty much all of the features the
databases covered have to offer.</p>

<p>So bear with me, I&#39;m on it.</p>

<p>The book is not built around the idea that a big application is to be built with
each database. I&#39;m not a fan of that approach myself, as it makes it too easy to
lose track of details. It&#39;s full of small examples, focused on specific
features.</p>

<p><strong>How many pages does it have?</strong></p>

<p>As the book is still growing, and I&#39;m still playing with layouting details, I
can&#39;t give you an exact number, but the final book is probably going to have
more than 200 pages.</p>

<p><strong>What&#39;s the pricing going to be?</strong></p>

<p>I haven&#39;t decided yet. It&#39;s not going to be in the single digits pricing range,
and as the book is pretty dense with content, I don&#39;t want to undercharge. I&#39;ll
keep you posted.</p>

<p><strong>Will there be early access to the book?</strong></p>

<p>Yes, there will be. You&#39;ll be able to buy the beta of the book for a reduced
price, and follow the updates. Maybe even the commits on GitHub? I don&#39;t know.
Let <a href="mailto:meyer@paperplanes.de">me know</a> if that&#39;s something you&#39;re interested
in.</p>

<p><strong>Do you have some samples I can peek at?</strong></p>

<p>Not yet. Layout is still far from final, but I&#39;ll throw something out as soon as
an early access will be available.</p>

<p><strong>What databases are being covered?</strong></p>

<p>To reach my goal for a final release, I&#39;m covering Redis, MongoDB, CouchDB,
Riak, and Cassandra, all in varying detail. For some it makes more sense to go
deeper than for others.</p>

<p><strong>Are future updates included?</strong></p>

<p>Yes, as content gets added, typos get fixed, and new databases pop up, I&#39;ll send
updates to everyone buying the book. The updates are free. Consider buying the
book a subscription for more chapters on other databases.</p>

<p><strong>Are you extending the book with more databases over time?</strong></p>

<p>Yes, I have an insatiable thirst to play with more databases, and I don&#39;t want
to deprive you of experiencing that too.</p>

<p><strong>Are you covering database SomeDB? I hear it&#39;s the next big thing!</strong></p>

<p>For now, the list of databases is fixed. What&#39;s coming after that, on the other
hand, is not. I&#39;m open to suggestions, but I&#39;d prefer some non-exotic over a
very domain-specific database you wrote for a recent project. I&#39;ll set up some
sort of voting when the final release is done.</p>

<p><strong>What formats will be available?</strong></p>

<p>I&#39;m currently working on PDF and ePub, with Kindle to follow. Gotta have my
priorities. A good-looking and readable PDF is my first priority, an ePub after
that. Buying the book includes access to all formats.</p>

<p><strong>Is there going to be a print edition?</strong></p>

<p>Print is not a priority right now.</p>

<p><strong>What are you using to write and generate the book?</strong></p>

<p>The book is written in Markdown (I hate LaTeX), converted to HTML using
<a href="https://github.com/tanoku/redcarpet">Redcarpet</a>, using
<a href="https://github.com/github/albino">Albino</a> for syntax-highlighting, and
converted to PDF using the awesome <a href="http://www.princexml.com/">Prince XML</a>
library, I hope to eventually use <a href="http://docraptor.com/">DocRaptor</a> to create
the final result, as a Prince license is slightly out of budget, but DocRaptor
is pretty affordable.</p>

<p><strong>Where can I get updates on progress?</strong></p>

<p>Mostly be following <a href="http://twitter.com/roidrage">me</a> or <a href="http://twitter.com/nosqlhandbook">the handbook
itself</a> on Twitter.</p>

      </div>
      <div class="item_meta">
        <span class="item_tags">
          Tags: 
          
        </span>
      </div>
    </div>
  </article>

  <article>
    <div class="item">
      <div class="item_details">
        <h3><a href="/2011/7/25/web_operations_101_for_developers.html">Web Operations 101 For Developers</a></h3>
        <h4><a href="/2011/7/25/web_operations_101_for_developers.html" title="Web Operations 101 For Developers">25 July 2011</a> by <a href="http://twitter.com/roidrage">Mathias Meyer</a></h4>
      </div>
      <div class="item_content">
        <p>This post is not about devops, it&#39;s not about lean startups, it&#39;s not about web
scale, it&#39;s not about the cloud, and it&#39;s not about continuous deployment. This
post is about you, the developer who&#39;s main purpose in life has always been to
build great web applications.  In a pretty traditional world you write code, you
write tests for it, you deploy, and you go home. Until now.</p>

<p>To tell you the truth, that world has never existed for me. In all of my
developer life I had to deal with all aspects of deployment, not just putting
build artifacts on servers, but dealing with network outages, faulty network
drivers, crashing hard disks, sudden latency spikes, analyzing errors coming
from those pesky crawling bots on that evil internet of yours. I take a lot of
this for granted, but working in infrastructure and closely with developers
trying to get applications and infrastructure up and running on EC2 has taught
me some valuable lessons to assume the worst. Not because developers are stupid, but
because they like to focus on code, not infrastructure.</p>

<p>But here&#39;s the deal: your code and all your full-stack and unit tests is worth
squat if they&#39;re not running out there on some server or infrastructure stack
like Google Apps or Heroku. Without running somewhere in production, your code
doesn&#39;t generate any business value, it&#39;s just a big pile of ASCII or UTF-8
characters that cost a lot of money to create, but didn&#39;t offer any return of
investment yet.</p>

<h3>Love Thy Infrastructure</h3>

<p>Operations isn&#39;t hard, but necessary. You don&#39;t need to know everything about
operations to become fluent in it, you just have to know enough to start and
know how to use Google.</p>

<p>This is my collective dump from the last years of working both as a developer
and that guy who does deployments and manages servers too. Most are lessons I
learned the hard way, others just seemed logical to me when I learned about them
the first time around.</p>

<p>Between you and me, having this skill set at hand makes you a much more valuable
developer. Being able to analyze any problem in production and at least having a
basic skill set to deal with it makes you a great asset for companies and
clients to hold on to. Thought you should know, but I digress.</p>

<p>The most important lesson I can tell you right up front: love your
infrastructure, it&#39;s the muscles and bones of your application, whereas your
code running on it is nothing more than the skin.</p>

<h3>Without Infrastructure, No-one Will Use Your Application</h3>

<p>Big surprise. For users to be able to enjoy your precious code, it needs to run
somewhere. It needs to run on some sort of infrastructure, and it doesn&#39;t matter
if you&#39;re managing it, or if you&#39;re paying another company to take care of it for
you.</p>

<h3>Everything Is Infrastructure</h3>

<p>Every little piece of software and hardware that&#39;s necessary to make your
application available to users is infrastructure. The application server serving
and executing your code, the web server, your email delivery provider, the
service that tracks errors and application metrics, the servers or virtual
machines your services are running on.</p>

<p>Every little piece of it can break at any time, can stall at any time. The more
pieces you have in your application puzzle, the more breaking points you have.
And everything that can break, will break. Usually not all at once, but most
certainly when it&#39;s the least expected, or just when you really need your
application to be available.</p>

<h3>On Day One, You Build The Hardware</h3>

<p>Everything starts with a bare metal server, even that cloud you&#39;ve heard so much
about. Knowing your way around everything that&#39;s related to setting up a full
rack of servers on a single day, including network storage a fully configured
switch with two virtual LANs and a master-slave database setup using a RAID 10
a bunch of SAS drives might not be something you need every day, but it sure
comes in handy.</p>

<p>The good news is the internet is here for you. You don&#39;t need to know everything
about every piece of hardware out there, but you should be able to investigate
strengths and weaknesses, when an SSD is an appropriate tool to use, and when
SAS drives will kick butt.</p>

<p>Learn to distinguish the different levels of RAID, why having an additional file
system buffer on top of a RAID that doesn&#39;t have a backup battery for its own,
internal write buffer is a bad idea. That&#39;s a pretty good start, and will make
decisions much easier.</p>

<h3>The System</h3>

<p>Do you know what swap space is? Do you know what happens when it&#39;s used by the
operating system, and why it&#39;s actually a terrible thing and gives a false sense
of security? Do you know what happens when all available memory is exhausted?</p>

<p>Let me tell you:</p>

<ul>
<li>When all available memory is allocated, the operating system starts swapping
out memory pages to swap space, which is located on disk, a very slow disk,
slow like a snail compared to fast memory.</li>
<li>When lots of stuff is written to and read from swap space on disk, I/O wait
goes through the roof, and processes start to pile up waiting for their memory
pages to be swapped out to or read from disk, which in turn increases load
average, and almost brings the system to a screeching halt, but only almost.</li>
<li>Swap is terrible because it gives you a false sense of having additional
resources beyond the available memory, while what it really does is slowing
down performance in a way that makes it almost impossible for you to log into
the affected system and properly analyze the problem.</li>
</ul>

<p>This is basically operations level on the operating system level. It&#39;s not much
you need to know here, but in my opinion it&#39;s essential. Learn about the most
important aspects of a Unix or Linux system. You don&#39;t need to know everything,
you don&#39;t need to know the specifics of Linux&#39; process scheduler or the
underlying datastructure used for virtual memory. But the more you know, the
more informed your decisions will be when the rubber hits the road.</p>

<p>And yes, I think enabling swap on servers is a terrible idea. Let processes
crash when they don&#39;t have any resources left. That at least will allow you to
analyze and fix.</p>

<h3>Production Problems Don&#39;t Solve Themselves</h3>

<p>Granted, sometimes they do, but you shouldn&#39;t be happy about that. You should be
willing to dig into whatever data you have posthumous to find whatever went wrong,
whatever caused a strange latency spike in database queries, or caused an
unusually high amount of errors in your application.</p>

<p>When a problem doesn&#39;t solve itself though, which is certainly the common case,
someone needs to solve it. Someone needs to look at all the available data to
find out what&#39;s wrong with your application, your servers or the network.</p>

<p>This person is not the unlucky operations guy who&#39;s currently on call, because
let&#39;s face it, smaller startups just don&#39;t have an operations team.</p>

<p>That person is you.</p>

<h3>Solve Deployment First</h3>

<p>When the first line of code is written, and the first piece of your application
is ready to be pushed on a server for someone to see, solve the problem of
deployment. This has never been easier than it is today, and being able to push
incremental updates from then on speeds up development and the customer feedback
cycle considerably.</p>

<p>As soon as you can, build that Capfile, Ant file, or whatever build and
deployment tools you&#39;re using, set up servers, or set up your project
on an infrastructure platform like <a href="http://scalarium.com">Scalarium</a>,
<a href="http://heroku.com">Heroku</a>, <a href="http://www.google.com/apps/">Google Apps</a>, or
<a href="http://dotcloud.com">dotCloud</a>. The sooner you solve this problem, the easier
it will be to finally push that code of yours into production for everyone to
use. I consider application deployment a solved problem. There&#39;s no reason why
you shouldn&#39;t have it in place even in the earliest stages of a project.</p>

<p>The more complex a project gets over even just its initial lifecycle the easier
it will be to add more functionality to an existing deployment setup instead of
having to build everything from scratch.</p>

<h3>Automate, Automate, Automate</h3>

<p>Everything you do by hand, you should only be doing once. If there&#39;s any chance
that particular action will be repeated at some point, invest the time to turn
it into a script. It doesn&#39;t matter if it&#39;s a shell, a Ruby, a Perl, or a Python
script. Just make it reusable. Typing things into a shell manually, or updating
configuration files with an editor on every single server is tedious work, work
that you shouldn&#39;t be doing manually more than once.</p>

<p>When you automate something once, it not only greatly increases execution speed the
second and third time around, it reduces the chance of failure, of missing that one
important step.</p>

<p>There&#39;s an abundance of tools available to automate infrastructure, hand-written
script are only the simplest part of it. Once you go beyond managing just one or
two servers, tools like <a href="http://www.opscode.com/chef/">Chef</a>,
<a href="http://www.puppetlabs.com/">Puppet</a> and
<a href="http://docs.puppetlabs.com/mcollective/">MCollective</a> come in very handy to
automate everything from setting up bare servers to pushing out configuration
changes from a single point, to deploying code. Everything should be properly
automated with some tool. Ideally you only use one, but looking at Chef and
Puppet, both have their strength and weaknesses.</p>

<p>Changes in Chef aren&#39;t instant, unless you use the command line tool <code>knife</code>,
which assumes SSH access to all servers you&#39;re managing. The bigger your
organizations the less chance you&#39;ll have to be able to access all machines via
SSH. Instant tools like mCollective that work based on a push agent system, are
much better for these instant kinds of activities.</p>

<p>It&#39;s not important what kind of tool you use to automate, what&#39;s important is
that you do it in the first place.</p>

<p>By the way, if your operations team restricts SSH access to machines for
developers, fix that. Developers need to be able to analyze and fix incidents
just like the operations folks do. There&#39;s no valid point in denying SSH access
to developers. Period.</p>

<h3>Introduce New Infrastructure Carefully</h3>

<p>Whenever you add a new component, a new feature to an application, you add a new
point of failure. Be it a background task scheduler, a messaging queue, an image
processing chain or asynchronous mail delivery, it can and it will fail.</p>

<p>It&#39;s always tempting to add shiny new tools to the mix. Developers are prone to
trying out new tools even though they&#39;ve not yet fully proven themselves in
production, or experience running them is still sparse. It&#39;s a good thing in one
way, because without people daring to use new tools everyone else won&#39;t be able
to learn from their experiences (you do share those experiences, do you?).</p>

<p>But on the other hand, you&#39;ll live the curse of the early adopter. Instead of
benefiting from existing knowledge, you&#39;re the one bringing the knowledge into
existence. You&#39;ll experience all the bugs that are still lurking in the darker
corners of that shiny new database or message queue system. You&#39;ll spend time
developing tools and libraries to work with the new stuff, time you could just
as well be spending working on generating new business value by using existing
tools that do the job similarly well. If you do decide for a new tool, be
prepared to degrade back to other tools in the case of failure.</p>

<p>No matter if old or new, adding more infrastructure always has the potential for
more things to break. Whenever you add something, be sure to know what you&#39;re
getting yourself into, be sure to have fallback procedures in place, be sure
everyone knows about the risks and the benefits. When something that&#39;s still
pretty new breaks, you&#39;re usually on your own.</p>

<h3>Make Activities Repeatable</h3>

<p>Every activity in your application that causes other, dependent activities to be
executed, needs to be repeatable, either by the user, or through some sort of
administrative interface, or automatically if feasible. Think user confirmation
emails, generating monthly reports, background tasks like processing uploads.
Every activity that&#39;s out of the normal cycle of fetching records from a
datasource and updating them is bound to fail. Heck, even that cycle will fail
at some point due to some odd error that only comes up every once in a blue
moon.</p>

<p>When an activity is repeatable, it&#39;s much easier to deal with outages of single
components. When it comes back up, simply re-execute the tasks that got stuck.</p>

<p>This, however, requires one important thing: every activity must be idempotent.
It must have the same outcome no matters how often it&#39;s being run. It must know
what steps were already taken before it broke the last time around. Whatever&#39;s
already been done, it shouldn&#39;t be done again. It should just pick up where it
left off.</p>

<p>Yes, this requires a lot of work and care for state in your application. But
trust me, it&#39;ll be worth it.</p>

<h3>Use Feature Flips</h3>

<p>New features can cause joy and more headaches. Flickr was one of the first to
add something called feature flips, a simple way to enable and disable features
for all or only specific users. This way you can throw new features onto your
production systems without accidentally enabling it for all users, you can
simply allow a small set of users or just your customer to use it and to play
with it.</p>

<p>What&#39;s more important though, when a feature breaks in production for some
reason, you can simply switch it off, disabling traffic on the systems involved,
allowing you to take a breether and analyze the problem.</p>

<p>Feature flips come in many flavors, the simplest approach is to just use a
configuration file to enable or disable them. Other approaches use a centralized
database like Redis for that purpose, which has an added benefit for other parts
of your application, but also adds new infrastructure components and therefore,
more complexity and more points of failure.</p>

<h3>Fail And Degrade Gracefully</h3>

<p>What happens when you unplug your database server? Does your application throw
in the towel by showing a 500 error, or is it able to deal with the situation
and show a temporary page informing the user of what&#39;s wrong? You should try it
and see what happens.</p>

<p>Whenever something non-critical breaks, your application should be able to deal
with it without anything else breaking. This sounds like an impossible thing to
do, but it&#39;s really not. It just requires care, care your standard unit tests
won&#39;t be able to deliver, and thinking about where you want a breakage to leak
to the user, or where you just ignore it, picking up work again as soon as the
failed component becomes available again.</p>

<p>Failing gracefully can mean a lot of things, there&#39;s things that directly affect
user experience, a database failure comes to mind, and things that the user will
notice only indirectly, e.g. through delays in delivering emails or fetching
data from an external service like Twitter, RSS feeds and so on.</p>

<p>When a major component in your application fails, a user will most likely be
unable to use your application at all. When your database latency increases
manifold, you have two options. Try to squeeze through as much as you can,
accepting long waits on your user&#39;s side, or you can let him know that it&#39;s
currently impossible to serve him in an acceptable time frame, and that you&#39;re
actively working on fixing or improving the situations. Which you should, either
way.</p>

<p>Delays in external services or asynchronous tasks are much harder for a user to
notice. If fetching data from an external source, like an API, directly affects
your site&#39;s latency, there&#39;s your problem.</p>

<p>Noticing problems in external services requires two things: monitoring and
metrics. Only by tracking queue sizes, latency for calls to external services,
mail queues and all things related to asynchronous tasks will you be able to
tell when your users are indirectly affected by a problem in your
infrastructure.</p>

<p>After all, knowing is half the battle.</p>

<h3>Monitoring Sucks, You Need It Anyway</h3>

<p>I&#39;ve written in <a href="http://www.paperplanes.de/2011/1/5/the_virtues_of_monitoring.html">abundance on the virtues of monitoring, metrics and
alerting</a>. I
can&#39;t say it enough how important having a proper monitoring and metrics gathering
system in place is. It should be by your side from day one of any testing deployment.</p>

<p>Set up alerts for thresholds that seem like a reasonable place to start to you.
Don&#39;t ignore alerting notifications, once you get into that habit, you&#39;ll miss
that one important notification that&#39;s real. Instead, learn about your system
and its thresholds over time.</p>

<p>You&#39;ll never get alerting and thresholds right the first time, you&#39;ll adapt over
time, identifying false negatives and false positives, but if you don&#39;t have a
system in place at all, you&#39;ll never know what hit your application or your
servers.</p>

<p>If you&#39;re not using a tool to gather metrics like
<a href="http://munin-monitoring.org/">Munin</a>,
<a href="http://ganglia.sourceforge.net/">Ganglia</a>, <a href="http://newrelic.com">New Relic</a>, or
<a href="http://collectd.org/">collectd</a>, you&#39;ll be in for a big surprise once your application becomes
unresponsive for some reason. You&#39;ll simply never find out what the reason was
in the first place.</p>

<p>While Munin has basic built-in alerting capabilities, chances are you&#39;ll add
something like <a href="http://www.nagios.org/">Nagios</a> or
<a href="http://www.pagerduty.com/">PagerDuty</a> to the mix for alerting.</p>

<p>Most monitoring tools suck, you&#39;ll need them anyway.</p>

<h3>Supervise Everything</h3>

<p>Any process that&#39;s required to be running at any time needs to be supervised.
When something crashes be sure there&#39;s an automated procedure in place that will
either restart the process or notify you when it can&#39;t do so, degrading
gracefully. <a href="http://mmonit.com/monit/">Monit</a>,
<a href="http://god.rubyforge.org/">God</a>, <a href="https://github.com/arya/bluepill">bluepill</a>,
<a href="http://supervisord.org/">supervisord</a>, <a href="http://smarden.org/runit/">RUnit</a>, the
number of tools available to you is endless.</p>

<p>Micromanaging people is wrong, but processes need that extra set of eyes on them
at all times.</p>

<h3>Don&#39;t Guess, Measure!</h3>

<p>Whatever directly affects your users&#39; experience affects your business. When
your site is slow, users will shy away from using it, from generating revenue
and therefore (usually) profit. </p>

<p>Whenever a user has to wait for anything, they&#39;re not willing to wait forever.
If an uploaded video takes hours to process, they&#39;ll go to the next video
hosting site. When a confirmation email takes hours to be delivered, they&#39;ll
check out your competitor, taking the money with them.</p>

<p>How do you know that users have to wait? Simple, you track how long things in
your application take, how many tasks are currently stuck in your processing
queue, how long it took to process an upload. You stick metrics on anything
that&#39;s directly or indirectly responsible for generating business value.</p>

<p>Without having a proper system to collect metrics in place, you&#39;ll be blind.
You&#39;ll have no idea what&#39;s going inside your application at any given time.
Since Coda Hale&#39;s talk <a href="http://codahale.com/codeconf-2011-04-09-metrics-metrics-everywhere.pdf">&quot;Metrics
Everywhere&quot;</a>
at CodeConf and the release of <a href="https://github.com/codahale/metrics">his metrics library for
Scala</a>, an abundance of libraries for
different languages has popped up left and right. They make it easy to include
timers, counters, and other types of metrics into your application,
allowing you to instrument code where you see fit. Independently, Twitter has
lead the way by releasing <a href="https://github.com/twitter/ostrich">Ostrich</a>, their
own Scala library to collect metrics. The tools are here for you. Use them.</p>

<p>The most important metrics should be easily accessible on some sort of
dashboard. You don&#39;t need a big fancy screen in your office right away, a
canonical place, e.g. a website including the most important graphs and numbers,
where everyone can go and see what&#39;s going on with a glance is a good start.
Once you have that in place, the next step towards a company-visible dashboard
is simple buying a big-ass screen.</p>

<p>All metrics should be collected in a tool like Ganglia, Munin or something else.
These tools make analysis of historical data easy, they allow you to make
predictions or correlate the metrics gathered in your applications to other
statistics like CPU, memory usage, I/O waits, and so on.</p>

<p>The importance of monitoring and metrics cannot be stressed enough. There&#39;s no
reason why you shouldn&#39;t have it in place. Setting up Munin is easy enough,
setting up collection using an external service like New Relic or
<a href="http://scoutapp.com">Scout</a> is usually even easier.</p>

<h3>Use Timeouts Everywhere</h3>

<p>Latency is your biggest enemy in any networked environment. It creeps up on you
like the shadow of the setting sun. There&#39;s a whole bunch of reasons why, e.g.
database queries will suddenly see a spike in execution time, or external
services suddenly take forever to answer even the simplest requests.</p>

<p>If your code doesn&#39;t have appropriate timeouts, requests will pile up and maybe
never return, exhausting available resources (think connection pools) faster
than Vettel does a round in Monte Carlo.</p>

<p>Amazon for example has internal contracts. Going to their home page involves
dozens of requests to internal services. If any one of them doesn&#39;t respond in a
timely manner, say 300 ms, the application serving the page will render a static
piece snippet instead, but thereby decreasing the chance of selling something,
directly affecting business value.</p>

<p>You need to treat every call to an external resource as something that can take
forever, something that potentially blocks an application server process
forever. When an application server process or thread is blocked, it can&#39;t serve
any other client. When all processes and threads lock up waiting for a resource,
your website is dead.</p>

<p>Timeouts make sure that resources are freed and made available again after a
grace period. When a database query takes longer than usual, not only does your
application need to know how to handle that case, but your database needs to. If
your application has a timeout, but your database will happily keep sorting those
millions of records in a temp file on disk, you didn&#39;t gain a lot. If two
dependent resources are within your hands, both need to be aware of contracts
and timeouts, both need to properly free resources when the request couldn&#39;t be
served in a timely manner.</p>

<p>Use timeouts everywhere, but know how to handle them when they occur, know what
to tell the user when his request didn&#39;t return quickly enough. There is no
golden rule what to do with a timeout, it depends not just on your application,
but on the specific use case.</p>

<h3>Don&#39;t Rely on SLAs</h3>

<p>The best service fails at some point. It will fail in the most epic way
possible, not allowing any user to do anything. This doesn&#39;t have to be your
service. It can be any service you directly or indirectly rely on.</p>

<p>Say, your code runs on Heroku. Heroku&#39;s infrastructure runs on Amazon&#39;s EC2.
Therefore Heroku is prone to problems with EC2. If a provider like Heroku tells
you they have a service level agreement in place that guarantees a minimum
amount of availability per month or per year, that&#39;s worth squat to you, because
they in turn rely on other external services, that may or may not offer
different SLAs. This is not specific to Heroku, it&#39;s just an obvious example.
Just because you outsourced infrastructure doesn&#39;t mean you&#39;re allowed to stop
caring.</p>

<p>If your application runs directly on EC2, you&#39;re bound by the same problem. The
same is true for any infrastructure provider you rely on, even a big hosting
company where your own server hardware is colocated.</p>

<p>They all have some sort of SLA in place, and they all will screw you over with
the terms of said SLA. When stuff breaks on their end, that SLA is not worth a
single dime to you, even when you were promised to get your money back. It will
never make up for lost revenue, for lost users and decreased uptime on your end.
You might as well stop thinking about them in the first place.</p>

<p>What matters is what procedures any provider you rely on has in place in case of
a failure. The important thing for you as one of their users is to not be left
standing in the rain when your hosting world is coming close to an end. A
communicative provider is more valuable than one that guarantees an impossible
amount of availability. Things will break, not just for you. SLAs give you that
false sense of security, the sense that you can blame an outage on someone else.</p>

<p>For more on this topic, Ben Black has written a
<a href="http://blog.b3k.us/2009/07/15/service-level-disagreements.html">two</a>
<a href="http://blog.b3k.us/2009/07/16/service-level-disagreements-2.html">part</a> series
aptly named &quot;Service Level Disagreements&quot;.</p>

<h3>Know Your Database</h3>

<p>You should know what happens inside your database when you execute any query.
Period. You should know where to look when a query takes too long, and you
should know what commands to use to analyze why it takes too long.</p>

<p>Do you know how an index is built? How and why your database picks one index over
another? Why selecting a random record based on the wrong criteria will kill
your database?</p>

<p>You should know these things. You should read &quot;High Performance MySQL&quot;, or
&quot;Oracle Internals&quot;, or &quot;PostgreSQL 9.0 High Performance&quot;. Sorry, I didn&#39;t mean
to say you should, I meant you must read them.</p>

<h3>Love Your Log Files</h3>

<p>In case of an emergency, a good set of log files will mean the world to you.
This doesn&#39;t just include the standard set of log files available on a Unix
system. It includes your application and all services involved too.</p>

<p>Your application should log important events, anything that may seem useful to
analyze an incident. Again, you&#39;ll never get this right the first time around,
you&#39;ll never know up front all the details you may be interested in later. Adapt
and improve, add more logging as needed. It should allow you to tune the log
verbosity at runtime, either by a using a feature switch or by accepting a Unix
signal.</p>

<p>Separate request logging from application logging. Data on HTTP requests is just
as important as application logs, but it&#39;s easier if you can sift through them
independently, they&#39;re also a lot easier to aggregate for services like Syslog
or Loggly when they&#39;re on their own.</p>

<p>For you Rails developers out there: using <code>Rails.logger</code> is not an acceptable
logging mechanism. All your logged statements will be intermingled with Rails
next to unusable request logging output. Use a separate log file for anything
that&#39;s important to your application.</p>

<p>Just like you should stick metrics on all things that are important to your
business, log additional information when things get out of hand. Correlating
log files with metrics gathered on your servers and in your application is an
incredibly powerful way of analyzing incidents, even long after they occurred.</p>

<h3>Learn the Unix Command Line</h3>

<p>In case of a failure, the command line will be your best friend. Knowing the
right tools to quickly sift through a set of log files, being able to find and
set certain kernel parameters to adjust TCP settings, knowing how get the most
important system statistics with just a few commands, and knowing where to look
for a specific service&#39;s configuration. All these things are incredibly valuable
in case of a failure.</p>

<p>Knowing your way around a Unix or Linux system, even with just a basic toolset
is something that will make your life much easier, not just in operations, but
also as a developer. The more tools you have at your disposal, the easier it
will be for you to automate tasks, to not be scared of operations in general.</p>

<p>In times of an emergency, you can&#39;t afford to argue that your favorite editor is
not installed on a system, you use what&#39;s available.</p>

<h3>At Scale, Everything Breaks</h3>

<p>Working at large scale is nothing anyone should strive for, it&#39;s a terrible
burden, but an incredibly fascinating one. The need for scalability evolves over
time, it&#39;s nothing you can easily predict or assume without knowing all the
details, parameters and the future. Out of all three, at least one is 100% guess
work.</p>

<p>The larger your infrastructure setup gets, the more things will break. The more
servers you have, the larger the number of servers being not available at any
time. That&#39;s nothing you need to respect right from the get go, it&#39;s something
to keep in mind.</p>

<p>No service that&#39;s working at a larger scale was originally designed for it. The
code and infrastructure were adapted, the services grew over time, and they
failed a lot. Something to think about when you reach for that awesome scalable
database before even having any running code.</p>

<h3>Embrace Failure</h3>

<p>The bottom line of everything is, stuff breaks, everything breaks at different
scale. Embrace breakage and failure, it will help you learn and improve your
knowledge and skill set over time. Analyze incidents using the data available to
you, fix the problem, learn your lesson, and move on.</p>

<p>Don&#39;t embrace one thing though: never let a failure happen again if you know
what caused it the first time around.</p>

<p>Web operations is not solely related to servers and installing software
packages. Web operations involves everything required to keep an application
available, and your code needs to play along.</p>

<h3>Required Reading</h3>

<p>As 101s go, this is a short overview of what I think makes up for a good starter
set of operations skills. If you don&#39;t believe or trust me (which is a good
thing), here&#39;s a list of further reading for you. By now, I consider most of
these required reading even. The list isn&#39;t long, mind you. The truth as of
today is still that you learn the most out of personal experience on production
systems. Both require one basic skill though: you have to want to learn.</p>

<ul>
<li><a href="http://www.amazon.com/gp/product/0978739213/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;tag=javaddicts-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0978739213">Release It!</a> - A must read, that&#39;s all I can say. It&#39;s an incredible resource stemming from years of production. A must read, no excuses.</li>
<li><a href="http://www.amazon.com/gp/product/1449377440/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;tag=javaddicts-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1449377440">Web Operations: Keeping the Data on Time</a> - The best summary on all things operations available today. If
you read one book, read this, and the previous one (that&#39;s two books, I know)</li>
<li><a href="http://www.amazon.com/gp/product/0974514039/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;tag=javaddicts-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0974514039">Pragmatic Project Automation</a> (oldie, but goldie, this book was an eye-opener to me)</li>
<li><a href="http://www.amazon.com/gp/product/0596518579/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;tag=javaddicts-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0596518579">The Art of Capacity Planning</a></li>
<li><a href="http://www.amazon.com/gp/product/0596102356/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;tag=javaddicts-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0596102356">Building Scalable Websites</a></li>
<li><a href="http://www.amazon.com/gp/product/B004PUIVLQ/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;tag=javaddicts-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B004PUIVLQ">High Performance MySQL, 2nd. Edition</a></li>
<li><a href="http://www.ctlab.org/documents/How%20Complex%20Systems%20Fail.pdf">How Complex Systems Fail</a></li>
<li><a href="http://www.usenix.org/event/lisa07/tech/full_papers/hamilton/hamilton_html/">On Designing and Deploying Internet-Scale Services</a></li>
</ul>

<p><br/></p>

<h2>Shameless Plug</h2>

<p>If you liked this article, you may enjoy the book I&#39;m currently working on: <a href="http://nosqlhandbook.com/">&quot;The NoSQL
Handbook&quot;</a>.</p>

      </div>
      <div class="item_meta">
        <span class="item_tags">
          Tags: 
          
        </span>
      </div>
    </div>
  </article>

</div>

<div class="pagination">
  
    
      <a href="/page26" class="previous">Newer Posts</a>
    
  
  
    <a href="/page28" class="next">Older Posts</a>
  
</div>

       
        <div id="footer">
          <div id="footer_text">
            <a href="/archives.html">Archives</a>, <a href="http://www.paperplanes.de/rss.xml" title="Full-text RSS feed">RSS Feed</a>, &copy; 2007-2014 Mathias Meyer <a href="/imprint.html">Imprint</a>
          </div>
        </div>
      </div>
    </div>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-46305173-1', 'paperplanes.de');
      ga('send', 'pageview');

    </script>
  </body>
  <script src="//my.hellobar.com/7db1d1ae6111ae95568efbbf8e6a1ee953ad854f.js" type="text/javascript" charset="utf-8" async="async"></script>
</html>
