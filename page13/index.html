<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <title>paperplanes. mathias meyer.</title>
    <meta name="robots" content="index,follow"/>
    <meta name="mssmarttagspreventparsing" content="true"/>
    <link rel="shortcut icon" href="/images/favicon.gif" type="image/gif" />
    <link rel="icon" href="/images/favicon.gif" type="image/gif" />
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
  	<meta name="author" content="Mathias Meyer"/>
    <meta name="dc.title" content="paperplanes. mathias meyer."/>
  	<link rel="start" href="http://www.paperplanes.de" title="paperplanes"/>
    
    <link href="http://www.paperplanes.de/rss.xml" rel="alternate" title="Primary Feed" type="application/rss+xml" />
    <link href="/stylesheets/screen.css" media="screen" rel="Stylesheet" title="paperplanes" type="text/css" />
    <link rel="stylesheet" type="text/css" href="/stylesheets/mobile.css" media="handheld, only screen and (max-device-width: 960px)" />
  </head>
  
  <body id="www-paperplanes-de">
    <div id="head">
      <div id="header-content">
        <a href="/">
          <img src="/images/paperplane.png" id="paperplane">
        </a>
        <div id="about">
          <h1 class="default">Hi, I'm Mathias Meyer, nice to meet you!</h1>
          <h1 class="mobile">Hi, I'm <a href="https://twitter.com/roidrage">Mathias Meyer</a>, I'm the CEO at <a href="https://travis-ci.com">Travis CI</a></h1>
          <p style="color: white" class="about-sub-title default">
            I'm the CEO at <a href="http://travis-ci.com">Travis CI</a>. I like coffee, <a href="https://twitter.com/roidrage">Twitter</a> and <a href="mailto:meyer@paperplanes.de">email</a>.
          </p>
        </div>
      </div>
    </div>

    <div id="box">
      <div id="content">
        <div id="articles">

  <article>
    <div class="item">
      <div class="item_details">
        <h3><a href="/2014/3/28/three-productivity-tips.html">Three Simple yet Incredibly Hard Productivity Tips</a></h3>
        <h4><a href="/2014/3/28/three-productivity-tips.html" title="Three Simple yet Incredibly Hard Productivity Tips">28 March 2014</a> by <a href="http://twitter.com/roidrage">Mathias Meyer</a></h4>
      </div>
      <div class="item_content">
        <p>Our working days (even our spare time and holidays) are filled with
distractions. Every social network that we used is fighting for our attention.
Plus, emails are always waiting to be replied to, archived or deleted. Push
notifications are constantly reminding us to reply to a friend, that one</p>

<p>Together, they&#39;ve formed the holy trifecta of distractions trying to pull us
away from getting work done.</p>

<p>Here are some simple yet incredibly hard suggestions:</p>

<ul>
<li><p><strong>Disable push notifications</strong> on your phone except for the most important
services.</p>

<p>I&#39;ve come to think of push notifications as <strong>push interruptions</strong>. They do
nothing but distract, they urge you to pick up your phone, to do something.
They directly appeal to our need for something new, something exciting.</p>

<p>I only have push notifications enabled for text messages these days and for
our alerting. If there&#39;s one thing I want to be made aware of, it&#39;s when
production is down.</p></li>
<li><p><strong>Avoid checking email first thing in the morning</strong></p>

<p>As helpful as email is in communicating, plowing through your morning inbox
sucks the bejesus out of your creativity. I found it to be poison for mine, in
particular getting started in the morning.</p>

<p>Rather than continuously have email open, only check it in intervals. If you
can&#39;t get used to that easily, set a timer, and don&#39;t break the timer.</p></li>
<li><p><strong>Kill Twitter, Facebook, and all the others</strong></p>

<p>Okay, this is harsh. But I found that Twitter is just as bad for my creativity
juice as reading email first thing. There&#39;s always a lot going on, which is
why we like checking our social network feeds in the first place.</p>

<p>And that&#39;s exactly what they prey on, our time, the little bit of attention we
can muster up to focus on something for a short period of time. I love reading
what&#39;s happening out there, but at the same time, I love getting work done.</p></li>
</ul>

<p>These steps sound so simple, yet they&#39;re incredibly hard. We get excited by the
thought of a new email bringing us good news, by a friend texting us or by
someone liking a photo. But does it really add anything so useful that it
warrants distracting us from what&#39;s really relevant?</p>

<p>I&#39;ve removed Twitter, Instagram, games, even email from my phone. It&#39;s quite
deliberating. It does turn an iPhone into a rather expensive two-factor
authentication device, but it removes a lot of pointless distractions.</p>

<p>Banksy says it best:</p>

<p><a href="https://twitter.com/thereaIbanksy/status/446832662330613760/photo/1"><img src="http://i.imgur.com/ZpR21Nz.jpg" alt=""></a></p>

<p>No more vibrating phone when an email comes in, when someone sends me a direct
message or likes a photo.</p>

<p>All that can wait. My focus can&#39;t.</p>

      </div>
      <div class="item_meta">
        <span class="item_tags">
          Tags: 
          
        </span>
      </div>
    </div>
  </article>

  <article>
    <div class="item">
      <div class="item_details">
        <h3><a href="/2014/3/27/building-an-ethical-business.html">Building an Ethical Business</a></h3>
        <h4><a href="/2014/3/27/building-an-ethical-business.html" title="Building an Ethical Business">27 March 2014</a> by <a href="http://twitter.com/roidrage">Mathias Meyer</a></h4>
      </div>
      <div class="item_content">
        <p>With our own company growing, both in terms of our team size and our customer
base, I keep finding myself thinking more about what kind of company we want it
to be.</p>

<p>This touches on all aspects of the business, relationships with our customers,
marketing our product, how we treat our community, both globally and locally,
and most importantly, treating and growing our team.</p>

<p>What it boils down to for me is openness on the one hand and fairness on the
other. Everywhere a company is active, there are always humans involved. Any
issues that come up are best served by being brought out in the open, treated
with empathy, the will to solve the problem, and the assumption that people are
generall well-intentioned in what they do.</p>

<p>This goes into all directions, because at the very core, empathy is the most
fundamental skill, both for the humans working in a company, and for the company
itself.</p>

<p>Empathy is sometimes described as a personal trait, but it&#39;s a skill, a skill
that can be learned, that can be honed, and that can be instilled as a core
value of a company.</p>

<p>Empathy means taking your customers&#39; issues seriously, acknowledging their
problems, helping them fix any issues they might have, no matter if the issue is
on their end or on yours.</p>

<p>Customer loyalty isn&#39;t something you can buy, it isn&#39;t something you can put a
number on. <strong>Customer loyalty is something you have to work on every single
day.</strong></p>

<p>Empathy means building relationships with your customers rather than look at
them as transactions. When they have issues, you have issues, it&#39;s simple as
that.</p>

<p>It also means that when there&#39;s a bigger issue at stake that affects your
company and your customers, it&#39;s tackled out in the open, head on, rather than
swept under the proverbial rug. This includes security issues,
operational/production issues, but also issues that affect your company in other
ways.</p>

<p>We like to think that a company&#39;s brand and image can be controlled. The more we
repeat our values, what we stand for, the more our customers will believe it.</p>

<p>That&#39;s bollocks. You can spend years trying to make yourself look pretty on the
outside, but that facade can be destroyed by that one small thing that you
didn&#39;t want to make public at the time.</p>

<p>Empathy means being open and honest about anything that affects your company.
Does that mean you have to tell the world exactly how much money you&#39;re making
or losing?</p>

<p>In what detail you make what you do public is up to you. We tend to fear that
publishing too much could play into the hands of our competitors, that it could
confuse customers, despite there being next to no proof this is actually the
case.</p>

<p>I admire <a href="http://open.bufferapp.com">Buffer&#39;s openness</a> in this regard. They&#39;re
publishing their team&#39;s salaries, the letters they send to their investors,
numbers about growth and losses. Can that hurt your company in any way? No one
knows, because it just hasn&#39;t been done before.</p>

<p>Empathy means that your company is aware of its surroundings. Even in times of
companies selling things to a global audience, with a distributed team,
companies have a home, where they pay taxes, and a community they&#39;re
inadvertently a part of.</p>

<p>An ethical business is about giving back to the community it&#39;s working in. I
found inspiration on this in &quot;The Knack&quot;, where the employees can get involved
in community work on the company&#39;s time, and they get to choose a good cause to
give something to at the end of the year.</p>

<p><a href="http://unicornfree.com/2013/the-responsibility-to-give-back-2013-charity-breakdown">Amy Hoy is doing something
similar</a>,
part of their profits go to local charities. I found this very inspirational,
and we started doing the same with part of our profits last year.</p>

<p>Beyond that, there&#39;s community work, helping kids and schools in need, lots of
opportunities to jump in and help out in a company&#39;s local surroundings.</p>

<p>Empathy means treating your vendors with the same courtesy as you treat your
customers. The same applies to them, you want to build relationships rather than
think of vendors as a transactional means for your business.</p>

<p>Vendors are people, just like your customers, the people in your community, the
people working in your company.</p>

<p>The people on your team are the most important for any company. Some would argue
differently, but I&#39;d say that for an ethical business, how you treat the people
working for you is what shapes any interaction your business has with its
surroundings, with its customers.</p>

<p>There&#39;s a quote in <a href="http://amzn.to/1d3lKOX">&quot;Small Giants&quot;</a> that stuck with me:</p>

<blockquote>
<p>For all the extraordinary service and enlightened hospitality that the small
  giants offer, what really sets them apart is their belief that the customer
  comes second.</p>
</blockquote>

<p>On first sight, it sounds harsh. Clearly, a business&#39; customers are the most
important for its continuing success, no?</p>

<p>It takes a happy and driven team to make for happy customers. Relationships can
only be made between humans. While customers can use your software or product,
or whatever it is you&#39;re selling, whenever they have issues, they expect a human
to help them out.</p>

<p>Building healthy relationships between your company and your customers requires
all people in  the company to have healthy relationships with each other, with
the people they work with, the people they work for.</p>

<p>Just like with your customers, you can&#39;t buy your team&#39;s loyalty. It requires
you to build relationships with them. Relationships are based on trust.</p>

<p>I&#39;d argue that you can only earn trust by putting your trust in someone in
return. Allowing people to do the right thing, yet still give them room to fail
and learn, is the simplest beginning to build trust.</p>

<p>When it comes to the people you work with, trust is reflected on different
levels, not just work, but also how your company treats their personal lives.</p>

<p>Trust, in turn, comes down to empathy.</p>

<p>Empathy is the recurring theme in this post, it&#39;s the recurring theme in any
human interaction. Empathy means you take your time to appreciate, to
contemplate what another person is thinking, what they&#39;re saying.</p>

<p>Whether it&#39;s your customers or one of the people you work with. Listening to
their concerns and treating them as if they&#39;re yours is the start of building
trust. If people learn that you can listen to them, without judgment, and help
them figure something out, you&#39;re off to a good start.</p>

<p>As Chad Fowler said, <a href="http://chadfowler.com/blog/2014/01/19/empathy/">empathy is your most important
skill</a>.</p>

<p>This is something I&#39;m trying to work on every day, work against my instincts,
listen to people first, ask questions, before I pass in my own view of
judgment. It&#39;s hard work.</p>

<p>For an ethical business, a lot of things come down to &quot;doing the right thing.&quot;</p>

<p>The right thing in the global, local or your company&#39;s micro scope can have lots
of different meanings, and figuring those out will be the hardest. We&#39;ve spent a
lot of time working that out for our little business, and we&#39;re still at the
very beginning.</p>

<p>Does an ethical company strive for profits? Of course, the question is how
they&#39;re used. A company needs cash to survive in the long run, but it also needs
to take care of its surroundings to function well.</p>

<p>What makes an ethical company then? I believe the <strong>core values lie in openness,
honesty and, most importantly, empathy</strong>. Those are skills that need to be
acquired, practiced and honed. We&#39;re only at the beginning of this journey for
ourselves, and we&#39;re working hard to stick to these values.</p>

      </div>
      <div class="item_meta">
        <span class="item_tags">
          Tags: 
          
        </span>
      </div>
    </div>
  </article>

  <article>
    <div class="item">
      <div class="item_details">
        <h3><a href="/2014/3/24/assessing-risk-in-socio-technical-systems.html">On Assessing Risk in Socio-Technical Systems</a></h3>
        <h4><a href="/2014/3/24/assessing-risk-in-socio-technical-systems.html" title="On Assessing Risk in Socio-Technical Systems">24 March 2014</a> by <a href="http://twitter.com/roidrage">Mathias Meyer</a></h4>
      </div>
      <div class="item_content">
        <p>I gave a talk about risk and safety in engineering at the DevOps user group in Frankfurt recently.</p>

<p>I talked about practical drift, normalization of deviance and the general ideas of risk and how complex systems make it almost impossible to predict all possible outcomes for a system running in production. The idea of the unknown unknowns (thanks, Donnie Rumsfeld!) and Black Swans (courtesy of <a href="http://amzn.to/19CvJvW" title="Nassim Taleb: The Black Swan - The Impact of the Highly Improbable">Nassim Taleb</a>) also came up.</p>

<p>A black swan, or an unknown unknown, is an event that is not just unlikely, no one has ever seen or consider it before. It&#39;s an accumulation of events so unlikely, that them coming together is beyond the risks anyone would normally consider, 9/11 comes to mind.</p>

<p>I had a chat with one attendee, who suggested that, before you build a system, you look at its properties and look at the possible influences of each one, considering the possible risks of things, going further and further back the causal chain of possible events that could lead up to an incident in the system to be designed and built.</p>

<p>As engineers, this seems like a plausible idea to us. You sit down, you look at your system from all known angles, you measure things, you apply some math here and there.</p>

<p>We like to think of engineering as a predictable practice. Once something&#39;s built with the right measurements, with the right tools and with a touch of craftsmanship, it&#39;ll last.</p>

<p>As a German, this idea certainly appeals to me. If there&#39;s anything we enjoy doing, it&#39;s building machines or parts for machines, or build machines to build parts of other machines.</p>

<h3>The Boeing wing test</h3>

<p><img src="http://s3itch.paperplanes.de/787-20130111-114538.png" alt=""></p>

<p>Take this picture, for instance. It&#39;s a magnificent sight, and it&#39;s a testimony to predictive engineering. It&#39;s the infamous wing test for the Boeing 787 Dreamliner.</p>

<p>For the test, the plane&#39;s wings are attached to a pretty impressive contraption. They&#39;re slowly pulled upwards to find the breaking point.</p>

<p>This test is intended to go way beyond the circumstances commonly found during normal flight operations, up to 150% above normal levels.</p>

<p>There&#39;s a video from a similar stress test for the Boeing 767 too. The wings break spectacularly at 154% beyond normal levels.</p>

<p>The engineers are cheering. The wings were built to withstand this kind of pressure, so it&#39;s only understandable, especially for us fellow engineers, that these guys are beyond happy to see their predictions realized in this test.</p>

<p>Ideally, you will never see wings being bent to these extremes.</p>

<p>Wings are but one piece in the big, complex system that is a modern plane.</p>

<p>A plane operates in an environment full of uncertainty. While we like to think we can predict the weather pretty well, its behavior cannot be controlled and can change in unpredicted, maybe even unprecendented ways. It is a system in itself.</p>

<p>This is where we come back to the idea that risk in complex systems can be assessed upfront, when designing, before building it.</p>

<p>A plane, on its own already a complex system, interacts with more complex systems. The humans steering it are one of them, the organization the pilots participate in are another. The weather is yet another complex system.</p>

<p>The interaction points of all these systems are almost boundless.</p>

<p>Engineers can try to predict all the possible states of a plane&#39;s operating environment. After all, someone is programming these states and the plane&#39;s responses to them.</p>

<p>But they can&#39;t predict how a human operator will interpret whatever information the system is presenting to them. Operating manuals are a common means to give us much insight as possible, but they&#39;re bound to what is known to the designer of the system before it is put into production use. </p>

<p>This is where socio-technical systems come into play. Technology rarely stands on its own, it interacts with human operators to get the job done. Together, they form a system that&#39;s shaped and driven both by technology and the social interactions in the organization operating it.</p>

<h3>Complex systems exist on the micro and the macro level</h3>

<p>A plane&#39;s wing is bound to wind, jet stream, speed, the material used to build it, the flaps to adjust the planes altitude. But it doesn&#39;t end there. It&#39;s bound to the care that was used building it, designing it, attaching it to the plane, the care of maintaining it.</p>

<p>With these examples along, the wing is part of several feedback loops. In &quot;Thinking in Systems&quot;, a feedback loop is how a system responds to changing conditions. The wing of a plane can respond to increasing pressure from upwards winds by simply bending. But as we&#39;ve seen above, it can only bend so far until it snaps.</p>

<p>But the wing is able to balance the increasing pressure nonetheless, helping to reduce impact of increasing wind conditions on the plane.</p>

<p>The wing then interacts with the plane, with its wheels, with its speed, its jet engines, its weight. The plane interacts with the pilots, it interacts with the wind, with the overall weather, with everchanging conditions around it.</p>

<p>The wing is therefore resilient. As per <a href="http://amzn.to/1k09Iic" title="Donella Meadows: Thinking in Systems - A Primer">&quot;Thinking in Systems&quot;</a>: </p>

<blockquote>
<p>Resilience is a measure of a system&#39;s ability to survive and persist within a variable environment. The opposite of resilience is brittleness and rigidity.</p>
</blockquote>

<p>A wing is a complex system on the macro level, and it is constructed of much smaller complex systems at the micro level. It&#39;s a complex system constructed of more complex systems. It&#39;s part of even bigger complex systems (the plane), that are bound to even more complex systems (the pilot, weather conditions, jet stream, volcano ash).</p>

<p>These systems interact with each other through an endless amount of entry and exit points. One system feeds another system.</p>

<p>Quoting from <a href="http://amzn.to/1k09Iic" title="Donella Meadows: Thinking in Systems - A Primer">&quot;Thinking in Systems&quot;</a>: </p>

<blockquote>
<p>Systems happen all at once. They are connected not just in one direction, but in many directions simultaneously.</p>
</blockquote>

<p><a href="http://amzn.to/1k09Iic" title="Donella Meadows: Thinking in Systems - A Primer">&quot;Thinking in Systems&quot;</a> talks about <strong>stock</strong> and <strong>flow</strong>. A stock is a system&#39;s capacity  to fulfill its purpose. Flow is an input and output that the system is able to respond to.</p>

<p>Stock is the wing itself, the material it&#39;s made of, whereas flow is a number of inputs and outputs that affect the stock. For instance, a type of input for a wing is speed of air flowing around it, another one the pressure built on it from the jet stream. The wing responds in different ways to each possible input, at least as far as it&#39;s been knowingly constructed for them.</p>

<p>If pressure goes up, the wing bends. If the flow of air is fast enough, the wing will drift, keeping the plane in the air.</p>

<p>Once you add more systems surrounding it, you increase the number of possible inputs and outputs. Some the wing knows how to respond to, others he may not.</p>

<blockquote>
<p>As systems become complex, their behavior can become surprising.</p>
</blockquote>

<p>The beauty of complex systems is, and this is a tough one to accept for engineers, the system can respond to certain inputs whether it was intended to do so or not.</p>

<blockquote>
<p>If pushed too far, systems may well fall apart or exhibit heretofore unobserved behavior. But, by and large, they manage quite well. And that is the beauty of systems: They can work so well. When systems work well, we see a kind of harmony in their functioning.</p>
</blockquote>

<p>With so many complex systems involved, how can we possibly try and predict all events that could feed into any of the systems involved, and how they then play into the other complex systems?</p>

<p>Our human brains aren&#39;t exactly built to follow a nearly infinite number of input factors that could contribute to an infinite number of possible outcomes.</p>

<blockquote>
<p>It&#39;s easier to learn about a systems elements than about its interconnections.</p>
</blockquote>

<h3>The Columbia disaster</h3>

<p>Let&#39;s dwell on the topic of wings for a minute.</p>

<p>During the Columbia crash on February 1, 2003, one of the low-signal problems the crew and mission control experienced were the loss of a few sensors in the left wing.</p>

<p>Those sensors indicated an off-scale low reading, indicating that the sensors were offline.</p>

<p>Going back to the launch, the left wing was the impact zone of a piece of foam the size of a suitcase, the risk of which was assessed but eventually deemed not to be hazardous to life.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Space_Shuttle_Columbia_disaster#Re-entry_timeline" title="Wikipedia: Space Shuttle Columbia disaster - Re-entry timeline">sensors went offline about five minutes before the shuttle disintegrated</a>. Around the same time, people watching the shuttle&#39;s reentry from the ground noticed that debris being shed.</p>

<p>The people at mission control didn&#39;t see these pictures, they were blind to what was going on with the shuttle.</p>

<p>Contact with the crew and the shuttle broke off five minutes later.</p>

<p>Mission control had no indication that the shuttle was going to crash. Their monitoring just showed the absense of some data, not all of it, at least initially.</p>

<p>A wing may just be one piece, but its connections to the bigger systems it&#39;s part of can go beyond what is deemed normal. Without any visuals, would you be able to assume that the shuttle is currently disintegrating, perishing the entire crew, just by seeing that a few sensors went offline?</p>

<h3>Constraints of building a system</h3>

<p>When we set out to build something, we&#39;re bound by cost. Most things have a budget attached to them.</p>

<p>How we design and build the system is bound by these constraints, amongst others.</p>

<p>If we were to sit down and try to evaluate all possible outcomes, we will eventually exhaust our budget before we even started building something.</p>

<p>Should we manage to come up with an exhaustive catalog of possible risks, we then have to design the system in a way that protects it from all of them.</p>

<p>This, in turn, can have the curious outcome that our system loses resilience. Protecting itself from all possible risks could end up creating a rigid system, one that is unable to respond to emerging risks by any other means than failing.</p>

<p>Therein lies the crux of complex systems and their endless possibilities of interacting with each other. When we try to predict all possible interactions, there will still be even more at some point in the future.</p>

<p>The conditions a system was designed for are bound to change over time as it is put into production use. Increasing usage, changing infrastructure, different operations personell, to name a few.</p>

<p>Weather changes because of climate change, and it takes decades for the effect to have any possible impact on our plane&#39;s wings.</p>

<h3>How complex systems fail</h3>

<p>With a sheer infinite amount of interactions and emerging inputs increasing them even further, the system can have an incredible amount of failure modes.</p>

<p>But, according to <a href="http://www.ctlab.org/documents/How%20Complex%20Systems%20Fail.pdf" title="Richard Cook, et. al.: How Complex Systems Fail">Richard Cook&#39;s &quot;How Complex Systems Fail&quot;</a>,</p>

<blockquote>
<p>Overt catastrophic failure occurs when small, apparently innocuous failures join to create opportunity for a systemic accident. Each of these small failures is necessary to cause catastrophe but only the combination is sufficient to permit failure.</p>
</blockquote>

<p>It requires multiple failures coming together for the system to fail.</p>

<p>With so many systems interacting with each other, predicting how and when a combination of failures is coming together feels beyond our mental capacity.</p>

<h3>The human factor</h3>

<p>What then holds our systems together when they&#39;re facing uncertainy in all directions?</p>

<p>Surprisingly, it&#39;s the human operator. Based on ever increasing exposure to and experience operating systems in production is a human the truly adaptable element in the system&#39;s equation.</p>

<blockquote>
<p>Recognizing hazard and successfully manipulating system operations to remain inside the tolerable performance boundaries requires intimate contact with failure.</p>
</blockquote>

<p>What is important for any organization is that these experiences are openly shared to increase overall exposure to these systems, to bring issues to light, to improve the system as its inputs and the system&#39;s response to them change over time. Because, depending on their exposure, the knowledge of the system&#39;s behaviour under varying circumstances can be unevenly spread.</p>

<p>Again, quoting from <a href="http://www.ctlab.org/documents/How%20Complex%20Systems%20Fail.pdf" title="Richard Cook, et. al.: How Complex Systems Fail">Cook</a>:</p>

<blockquote>
<p>Recognizing hazard and successfully manipulating system operations to remain inside the tolerable performance boundaries requires intimate contact with failure.</p>
</blockquote>

<p>Following this, maybe <strong>designing systems should focus more on building them with the human operator in mind</strong> than trying to protect them from as many possible causes of failure as possible, including the human operator.</p>

<h3>Organization culture and risk</h3>

<p>Assuming your organization has a good track record when it comes to safety and assessing risk. Is that an indicator that future projects are in good hands? Is a history of risk assessment and safety enough to warrant continuing safety?</p>

<p>According to <a href="http://www.ctlab.org/documents/How%20Complex%20Systems%20Fail.pdf" title="Richard Cook, et. al.: How Complex Systems Fail">Cook</a>:</p>

<blockquote>
<p>People continuously create safety.</p>
</blockquote>

<p>Subsequently, a good safety track record is no indication for the future. Safety is not a one-time purchase, it is a continuing process that shifts between production and monetary pressure, people&#39;s work load, and any activity at the sharp end, on the production system.</p>

<p>The Challenger incident is an interesting example here. On January 26, 1986, the Challenger shuttle lifted off the launchpad, only to be disintegrated in the atmosphere 73 seconds later. The flight&#39;s designation was <a href="https://en.wikipedia.org/wiki/STS-51-L" title="Wikipedia: Shuttle Transportation System 51-L">STS-51-L</a>.</p>

<p>NASA, going back to the Apollo program, inarguably has a history of successfully finishing missions, even to the moon. They had good experience constructing and running hazardous equipment in production.</p>

<p>But, with the Shuttle program, the organization found itself in different circumstances. Stemming from the Vietnam war, budgets were cut significantly, staff shrank to about 1/3 of its original size as a consequence.</p>

<p>NASA relied a lot more on external contractors to work on specific parts of the Space Shuttle, just like the solid booster rockets propelling the shuttle into the atmosphere.</p>

<p>For budget reasons, the rockets&#39; design was based on the Titan rocket, the booster rocket used in the Apollo program. Everyone at NASA assumed that the rockets were not only a good fit, but that there was sufficient experience with them in the organization.</p>

<p>Something else was different with the Shuttle program. NASA suddenly found itself under production pressure from potential customers. The program was aimed to be as economical as possible, with up to 50 launches per year to make sure that costs are fully covered by revenue. The US Army was very much interested in using the Shuttles as a means of transporting satellites and other gear into space.</p>

<p>Following the changes in production pressure and working with more external contractors, NASA introduced a bigger management structure. Four layers of managers and sub-managers eventually existed at NASA, with every sub-manager reporting up the stream, representing their own teams.</p>

<p>When the first Shuttles were launched, the team responsible for the booster rockets noticed behaviour that was different from their experience in the Apollo program.</p>

<p>The joints holding the parts of the rockets together were rotating, the O-rings sealing the joints of the parts either burnt through under certain circumstances, or they behaved in unexpected ways at very low temperatures. When rubber gets below certain temperatures, it stiffens up, making it unable to move an potentially fulfill its duty.</p>

<p>Most conditions were only seen in isolation rather than together affecting a single flight. For most of them, the team thought they understood their respective risks.</p>

<p>All these issues were known to the engineering teams involved, they were even considered critical to human life.</p>

<p>Before every launch, NASA held an assessment meeting where all critical issues were discussed. The issues found by the solid booster rockets were brought up regularly in the summaries given by their respective managers. There were slides showing notes on the issue, and the risk was discussed as well.</p>

<p>With every launch, the engineers learned a few new things about the behaviour of the solid booster rocket. Some of these things made it up the reporting chain, others didn&#39;t.</p>

<p>On the evening of the fatal Challenger launch, the teams came together to talk about the final go or no go.</p>

<p>A few of the engineers from the contracting companies had doubts about the launch, as the forecast for Cape Canneveral predicted very low temperatures, lower than during any previous launch of a Space Shuttle.</p>

<p>While the engineers voiced their concerns and initially suggested to delay the launch, management eventually overruled them and gave the go for launch.</p>

<p>Again from <a href="http://www.ctlab.org/documents/How%20Complex%20Systems%20Fail.pdf" title="Richard Cook, et. al.: How Complex Systems Fail">Richard Cook</a>:</p>

<blockquote>
<p>All ambiguity is resolved by actions of practitioners at the sharp end of the system.</p>
</blockquote>

<p>There were a lot of miscommunication issues involved in this meeting alone, but the issue goes much deeper. The layers of management within the organization added an unintended filtering mechanisms to safety issues and risks.</p>

<p>During presentations in assessment and pre-launch meetings, information was usually presented in slide form. In the Challenger days, they used overhead projectors, during later years, engineers and management resorted to using PowerPoint.</p>

<p>Regardless of the tool, the information was presented in a denser form (denser with every management layer), using bullet points, with several things compacted into a single slide.</p>

<p>This had the curios effect of losing salience for the relevant information, the data that possibly could have indicated real risks rather than intermingle them with other information.</p>

<p>The Columbia accident suffered from similar problems. From the <a href="http://spaceflight.nasa.gov/shuttle/archives/sts-107/investigation/CAIB_lowres_full.pdf" title="Columbia Accident Investigation Board: Report Vol. 1">Columbia Accident Investigation Board&#39;s Report Vol. 1</a>:</p>

<blockquote>
<p>As information gets passed up an organization hierarchy, from people who do analysis to mid-level managers to high-level leadership, key explanations and supporting information is filtered out. In this context, it is easy to understand how a senior manager might read this PowerPoint slide and not realize that it addresses a life-threatening situation.</p>
</blockquote>

<p>Edward Tufte has <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001yB&amp;topic_id=1" title="Edward Tufte: PowerPoint Does Rocket Science">written an excellent analysis</a> of the use of PowerPoint to assess the risk of the Columbia incident. Salience and losing detail in condensed information play a big part in it.</p>

<p>The bottom line is that even in the most risk-aware organizations and hazardous environments, assessing safety is an incredibly hard but continuous process. Your organization can drift into a state where a risky component or behaviour becomes the norm.</p>

<p>In <a href="http://amzn.to/1fEZykf" title="Diane Vaughan: The Challenger Launch Decision: Risky Technology, Culture, and Deviance at NASA">&quot;The Challenger Launch Decision&quot;</a>, Diane Vaughan coined the term <strong>&quot;normalization of deviance.&quot;</strong> What used to be considered a risk has now become a normal part of the system&#39;s accepted behaviour.</p>

<p>Scott Snook later improved it to <a href="http://amzn.to/15bQMAj" title="Scott Snook: Friendly Fire - The Accidental Shootdown of U.S. Black Hawks over Northern Iraq"><strong>&quot;practical drift&quot;</strong></a>, <em>&quot;the slow steady uncoupling of practice from written procedure.&quot;</em></p>

<p>Sidney Dekker later made it even more concrate and coined the term <a href="http://amzn.to/1k0cLaf" title="Sidney Dekker: Drift into Failure"><strong>&quot;drift into failure&quot;</strong></a>, <em>&quot;a gradual, incremental decline into disaster driven by environmental pressure, unruly technology and social processes that normalize growing.&quot;</em></p>

<p>How do you prevent practical drift or drift into failure? Constant awareness, uncondensed sharing of information, open feedback loops, reducing procedural friction, loose layers, involved the people at the sharp end of the action as much as possible, written reports instead of slide decks as suggested by <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001yB&amp;topic_id=1" title="Edward Tufte: PowerPoint Does Rocket Science">Tufte</a>?</p>

<p>Maybe all of the above. I&#39;d be very interested in your thoughts and experiences.</p>

      </div>
      <div class="item_meta">
        <span class="item_tags">
          Tags: 
          
        </span>
      </div>
    </div>
  </article>

</div>

<div class="pagination">
  
    
      <a href="/page12" class="previous">Newer Posts</a>
    
  
  
    <a href="/page14" class="next">Older Posts</a>
  
</div>

       
        <div id="footer">
          <div id="footer_text">
            <a href="/archives.html">Archives</a>, <a href="http://www.paperplanes.de/rss.xml" title="Full-text RSS feed">RSS Feed</a>, &copy; 2007-2014 Mathias Meyer <a href="/imprint.html">Imprint</a>
          </div>
        </div>
      </div>
    </div>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-46305173-1', 'paperplanes.de');
      ga('send', 'pageview');

    </script>
  </body>
  <script src="//my.hellobar.com/7db1d1ae6111ae95568efbbf8e6a1ee953ad854f.js" type="text/javascript" charset="utf-8" async="async"></script>
</html>
